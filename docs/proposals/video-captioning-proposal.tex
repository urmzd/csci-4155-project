\documentclass[11pt]{article}
\usepackage[noblocks]{authblk}
\title{Automated Close Captioning}
\author[1]{Urmzd Mukhammadnaim \thanks{urmzd@dal.ca, B00800045}}
\author[1]{Keelin Sekerka-Bajbus \thanks{kl967083@dal.ca, B00739421 }}
\author[1]{Benjamin J. Macdonald \thanks{bn282348@dal.ca, B00803015}}

\affil[1]{Faculty of Computer Science, Dalhousie University}
\setcounter{secnumdepth}{0}
\begin{document}
\maketitle

\section{Motivation}
According to a meta-study done by Nucleus Research [cite], two-thirds
of online transactions are abandoned by blind individuals due to the lack of accessibility.
Furthemore, approximately 36 million are said to have some degree of visual impairment, with the number
expected to triple by 2050 according to a statistic by the World Health Organization.
With a spending power of almost half a trillion dollars a year, providing accessibility
as a service to individuals with disabilities is a untapped market that is by large, not catered to.
Furthermore, as the pandemic has forced human interactions to be in large part, remote, accessibility is no longer
a privilege, but a basic human right. This project proposes a tool to begin enabling better accessibility
integration on video-streaming platforms such as Netflix and YouTube, through the automated
closed captioning of videos. More specifically, given a short video clip, we propose a model which
can generate a single sentence describing the events in the input. 

\section{Data Collection and Processing}




\end{document}
